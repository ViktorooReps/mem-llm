{
  "training_steps": 2000,
  "cooldown_steps": 0.2,
  "warmup_steps": 0.1,
  "eval_steps": 50,
  "eval_per_steps": 200,
  "checkpoint_per_steps": 1000,
  "keep_only_last_checkpoint": true,
  "use_muon": false,
  "adamw_learning_rate": 0.005,
  "adamw_beta1": 0.9,
  "adamw_beta2": 0.99,
  "adamw_wd": 0.01,
  "max_grad_norm": 1.0,
  "model_type": "custom",
  "dataset_config": {
    "dataset_name": "tiny-shakespeare",
    "example_length": 16000
  },
  "model_config": {
    "n_q_heads": 8,
    "n_kv_heads": 4,
    "head_dims": 128,
    "mlp_hidden_dims_expansion": 2.0,
    "rotary_inv_freq_base": 1000000.0,
    "n_layers": 24,
    "local_window": 512,
    "global_window": null,
    "mem_freq": 10000000000,
    "precompute_mem": false,
    "torch_dtype": "bfloat16",
    "unet_design": false,
    "embeds_residual": false,
    "do_compile": true
  },
  "do_compile": true,
  "tokenizer_type": "char",
  "tokenizer_config": {
    "vocab_size": 128
  },
  "log_per_steps": 50,
  "disable_progress_bar": true,
  "rewrite_metrics": true,
  "num_dataloader_workers": 4,
  "dataloader_prefetch_factor": 8,
  "start_local_window_size": null,
  "end_local_window_size": null,
  "local_window_warmup_steps": 0,
  "start_global_window_size": null,
  "end_global_window_size": null,
  "global_window_warmup_steps": 0,
  "start_mem_freq": null,
  "end_mem_freq": null,
  "mem_freq_warmup_steps": 0
}
