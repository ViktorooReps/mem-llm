{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-17T12:48:57.916139Z",
     "start_time": "2024-12-17T12:48:54.609340Z"
    }
   },
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from mem_llm.tokenizer import CharTokenizer\n",
    "from mem_llm.interface import ModelOutput\n",
    "\n",
    "from mem_llm import MemLLM"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Inference",
   "id": "980b156dcced63b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:02:50.136645Z",
     "start_time": "2024-12-17T13:02:50.130300Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.distributions import Categorical\n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(\n",
    "        seed: str,\n",
    "        model: torch.nn.Module,\n",
    "        tokenizer: CharTokenizer,\n",
    "        *,\n",
    "        device: str,\n",
    "        max_length: int,\n",
    ") -> str:\n",
    "    model.eval()\n",
    "    model.to(device)\n",
    "    \n",
    "    model.do_compile = True\n",
    "\n",
    "    tokens = tokenizer.encode(seed).to(device)\n",
    "    print(seed, end='')\n",
    "\n",
    "    for _ in range(max_length):\n",
    "        outputs = model(tokens, num_logits_to_keep=1)\n",
    "        outputs: ModelOutput\n",
    "    \n",
    "        logits = outputs.logits.view(1, -1)\n",
    "        topk_logits, topk_indices = torch.topk(logits, k=10, dim=-1)\n",
    "    \n",
    "        probs = torch.softmax(topk_logits, dim=-1)\n",
    "    \n",
    "        next_token_id = Categorical(probs).sample()\n",
    "        best_next_char = topk_indices[0, next_token_id]\n",
    "    \n",
    "        tokens = torch.concat((tokens, best_next_char), dim=0)\n",
    "    \n",
    "        print(tokenizer.decode(best_next_char), end='')\n",
    "        \n",
    "    return tokenizer.decode(tokens)"
   ],
   "id": "b5d0e745fe239327",
   "outputs": [],
   "execution_count": 31
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:13:44.546224Z",
     "start_time": "2024-12-17T13:13:43.252484Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MemLLM.load('../runs/char_lm/ts_from_scratch/model', device='cuda')\n",
    "tokenizer = CharTokenizer.load('../runs/char_lm/ts_from_scratch/model')"
   ],
   "id": "5ea4122e6bbd8ff9",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:17:09.020442Z",
     "start_time": "2024-12-17T13:13:44.547755Z"
    }
   },
   "cell_type": "code",
   "source": "generate('O God! O God! ', model, tokenizer, device='cuda', max_length=2000);",
   "id": "4d4e730e596a4f0a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O God! O God! what comfort on?\n",
      "What! it didst did stone? and hateful friends?\n",
      "Mush to am I.\n",
      "\n",
      "SICINIUS:\n",
      "You will speak as you of a file; but I am,\n",
      "Your bidding true, bestrong you to make your diggers,\n",
      "Ere you not set too city flight too great,\n",
      "And you will me such merrieve to guests;\n",
      "Sufferant a watering dates charity?\n",
      "When they say is that? Mismicker your commanded?\n",
      "You willingly minds in yours, believe here!\n",
      "By that shall give me much of your grace,\n",
      "But you shall have told me scarce more than you.\n",
      "Beating than I a fine, at wavers my heart\n",
      "That lies incilict of the present looks,\n",
      "But fly thee pessing my daughter of the lume\n",
      "Of disgrains gold the law of your countenation,\n",
      "By the ground that they do no great mother forth,\n",
      "He do tomorrow many wounds to do it.\n",
      "\n",
      "First Murderer:\n",
      "So now, by God's grave! I have that might soul,\n",
      "How not it will be our book'd trial, we know,\n",
      "And I am sure to death this marriage words,\n",
      "From my dear good since, whom I all said,\n",
      "That setter like a scenen's biggest again;\n",
      "But bid us mother, I will bring all the chider;\n",
      "For I have devoted says they are took.\n",
      "\n",
      "First Senator:\n",
      "Madam, with a cremissing dam, before my limb!\n",
      "\n",
      "BRINCE EDWARD:\n",
      "You may dispair will seal for a mad-let us so.\n",
      "\n",
      "QUEEN MARGARET:\n",
      "I am gladly son on holy son.\n",
      "\n",
      "Second Murderer:\n",
      "I have say'd the character of a meanings?\n",
      "\n",
      "KATHARINA:\n",
      "Weeping be safety, like a good and me;\n",
      "For I hate to make overtimented in this!\n",
      "\n",
      "Second Gentleman:\n",
      "The crown of love, and looked the solvey again.\n",
      "\n",
      "GREGORIA:\n",
      "They come to get him thee, loss that they\n",
      "That love this dagger here.\n",
      "\n",
      "CLARENCE:\n",
      "As them affection that to hear me show.\n",
      "Sir, my lord, in tender of sing be at\n",
      "Inficerty will cur thy footing.\n",
      "\n",
      "MENENIUS:\n",
      "It was betimes now, my heart with my brothers.\n",
      "Thou hast heed that thou art a god.\n",
      "\n",
      "CARIOLANUS:\n",
      "Then before I lose him in myself, and I have remorsed\n",
      "To all the feeding and old but framed love,\n",
      "And love the destinous on him, and twain any father\n",
      "Threat our holy-shot, surely in the great hand;\n",
      "The show is nothing tha"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:17:09.100735Z",
     "start_time": "2024-12-17T13:17:09.021812Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MemLLM.load('../runs/char_lm/ts_finetune/model', device='cuda')\n",
    "tokenizer = CharTokenizer.load('../runs/char_lm/ts_finetune/model')"
   ],
   "id": "5090e03320a9d41a",
   "outputs": [],
   "execution_count": 54
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:20:31.189318Z",
     "start_time": "2024-12-17T13:17:09.102073Z"
    }
   },
   "cell_type": "code",
   "source": "generate('O God! O God!', model, tokenizer, device='cuda', max_length=2000);",
   "id": "48ef2bf799eac605",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O God! O God!\n",
      "William God hath behoved the bride.\n",
      "Must not be taught at all, God hath met his bride.\n",
      "\n",
      "CAPULET:\n",
      "O God! my son, God! sir.\n",
      "\n",
      "God! my face to my captain;\n",
      "O God! my son.\n",
      "\n",
      "MUSTOCAPE\n",
      "\n",
      "ISABELLA:\n",
      "The captain offers a period of written darkness:\n",
      "I speaks it wrong in your mother's breast,\n",
      "Holy for them as methinks: if you heaven stirr'd in\n",
      "This wounds into one; indeed, you must not keep\n",
      "The melody of God, Giod God! I sent me fingers too,\n",
      "To that too.\n",
      "Will not thou taught you spoke:\n",
      "You must have you a bit of here.\n",
      "\n",
      "MUSTOCAPE:\n",
      "I speak you\n",
      "To God. Will I love your cousin?\n",
      "\n",
      "BULLIONS:\n",
      "And state thy mate! I must speak in thy prayer:\n",
      "You have thus taken him seriously.\n",
      "\n",
      "CAPULET:\n",
      "Although I, till morn's say we are all good about\n",
      "Take the same way as he be animal, I'll do so.\n",
      "\n",
      "ASIDE:\n",
      "O God!\n",
      "\n",
      "CAPULET:\n",
      "And nobust the god of how you are, Giod God!\n",
      "\n",
      "CAPULET:\n",
      "You done sadness, I shall go on.\n",
      "\n",
      "CAPULET:\n",
      "As taught, these are thus! well, if I, thou cannot stay,\n",
      "Yet speak, Giod God!\n",
      "\n",
      "CAPULET:\n",
      "I'le to my captain,\n",
      "I cannot come the god, Giod God, to stand the sea\n",
      "To blow the shoulders of God; and well stir,\n",
      "To block myself at the shoulders of this practice.\n",
      "\n",
      "CAPULET:\n",
      "And stay that thou canst drink away.\n",
      "\n",
      "CAPULET:\n",
      "Master, sadness, to be taken, my true apprehender;\n",
      "My love's fearful death is counted up, and that if\n",
      "you have seen these great triumphs\n",
      "I have depopulated my philosophy.\n",
      "\n",
      "CAPULET:\n",
      "Now, thou cannot see?\n",
      "\n",
      "BULLIONS:\n",
      "And now, sir, now we'll be the thing.\n",
      "Yet thou, the man truth will, that thou to be here.\n",
      "If thou cannot convey the teachings, thou torroo!\n",
      "Yet thou will say 'tis some man thou wit death,' another\n",
      "man, whateous thou cannot death.\n",
      "\n",
      "CAPULET:\n",
      "Thou willst grow through my dear shock!\n",
      "\n",
      "BULLIONS:\n",
      "You may think a true; for thou speak'st.\n",
      "\n",
      "SECRET:\n",
      "And it is my life, and she'd weep in her text;\n",
      "And she'd weep some message to slurr;\n",
      "But not to-morrow to sleep, and both.\n",
      "\n",
      "CAPULET:\n",
      "In her hope, thou darest perimeter dead,\n",
      "Tis while, that thou king'st, a flower which\n",
      "If she were to-morrow's"
     ]
    }
   ],
   "execution_count": 55
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T12:49:05.521835Z",
     "start_time": "2024-12-17T12:49:05.166340Z"
    }
   },
   "cell_type": "code",
   "source": [
    "model = MemLLM.load('../runs/char_lm/mem_unet_embed/model', device='cuda')\n",
    "tokenizer = CharTokenizer.load('../runs/char_lm/mem_unet_embed/model')"
   ],
   "id": "582182e5c98c5bd2",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:06:13.052464Z",
     "start_time": "2024-12-17T13:02:52.323401Z"
    }
   },
   "cell_type": "code",
   "source": "generate('O God! O God! ', model, tokenizer, device='cuda', max_length=2000);",
   "id": "f59c0579d6d54ef9",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O God! O God! The God was an American civil society. However, a number of people who were not accountable for there was a great advantage to an economic change and the gap of economic process and trade. On the other hand, it was a spiritual policy. But in the Gospel and Mrs. Ben Goddard, traditional legislator, for the second century of the God and because there would not be a man or a few important parts. It is essential to earn an organisation that the God's bureau in the Greek province and the God, was a guardian political and a past so what, in a disagreement, a total of the Gospel. When the Gospel successfully suffered the Gospel with this influence and, when we had talked to musical and traditional monuments, the Gospels had not done. Out of God's stuck being handed out in agriculture, there were several persons who were irritated.\n",
      "Above all, the Gospel was soon able to grow and submit, and then several Gods speaking agreements were alike, in the Gospel. The Gospel was able to find in the Gospel to the standing of all the Gospels of God, the Gospels and the Gospel after the death of Mrs. Ben Goddard, the Greeks, and the Gospel in God to commit to God, and some God told them that God was the bureau of God hunting again and that God's bureau was the second Gospel. By God, he was suffering in the Gospel to God, and he was out of the Gospel the Gospel and the Gospel. Ordinary Gospel who was brought to agriculture hidden with tradition, was not a short-cathed coming from Gospel from God, but with no proprietarian service or the situation. After which God struated God, since there is a ritual of God, and whose work in God is to say, God was sick and therefore wounded, as some God. Those soldiers were fluctuated.\n",
      "So, God had been trying to take a God as short and still remain on the welsity of God, as thought of signal-irritating God's work being inspired by that which she'll appear. His work was also a member of the Gospel, the Gospel, and the Gospel as God won the same year. Go "
     ]
    }
   ],
   "execution_count": 32
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:06:32.492813Z",
     "start_time": "2024-12-17T13:06:22.685836Z"
    }
   },
   "cell_type": "code",
   "source": "generate('How many \"r\" are in the \"strawberry\"?', model, tokenizer, device='cuda', max_length=100);",
   "id": "4c6213c183bd6f81",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How many \"r\" are in the \"strawberry\"?\n",
      "How does \"r\" are in the strawberry flow facing organ. What are the different functions of product o"
     ]
    }
   ],
   "execution_count": 33
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:51.332711Z",
     "start_time": "2024-12-17T13:08:51.229491Z"
    }
   },
   "cell_type": "code",
   "source": "generate('Let N be the number of \"r\" are in the \"strawberry\". We can calculate N=', model, tokenizer, device='cuda', max_length=1);",
   "id": "ec1b4a022b0d3463",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Let N be the number of \"r\" are in the \"strawberry\". We can calculate N=2"
     ]
    }
   ],
   "execution_count": 50
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:09:53.709651Z",
     "start_time": "2024-12-17T13:09:53.573604Z"
    }
   },
   "cell_type": "code",
   "source": "generate('Everyone knows that 1 + 1 = ', model, tokenizer, device='cuda', max_length=1);",
   "id": "fa127516394a6ec6",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everyone knows that 1 + 1 = 4"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Ablation study",
   "id": "363f3adb3be8f3a7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T14:05:27.430870Z",
     "start_time": "2024-12-17T14:04:33.329937Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import math\n",
    "from torch.utils.data import DataLoader\n",
    "import json\n",
    "from pathlib import Path\n",
    "from mem_llm.dataset import GuaranteedLengthDataset\n",
    "import numpy as np\n",
    "import torch\n",
    "from mem_llm import MemLLM\n",
    "import pandas as pd\n",
    "\n",
    "torch.set_float32_matmul_precision('medium')\n",
    "\n",
    "experiments = [\n",
    "    'mem',\n",
    "    'mem_unet',\n",
    "    'baseline_rope1m',\n",
    "    'baseline_rope10k',\n",
    "    'baseline_rope500',\n",
    "    'baseline_unet_embed',\n",
    "    'mem_unet_embed',\n",
    "]\n",
    "\n",
    "@torch.no_grad()\n",
    "def evaluate(path: Path):\n",
    "    print(path)\n",
    "    model = MemLLM.load(path / 'model', device='cuda')\n",
    "    \n",
    "    model.eval()\n",
    "    model = torch.compile(model.to('cuda'))\n",
    "    \n",
    "    val_dataset = GuaranteedLengthDataset(\n",
    "        '../data/fineweb-edu__char-vocab_size128-unk_token0-eos_token_id127/val', \n",
    "        example_length=100000, \n",
    "        source_dtype=np.uint8\n",
    "    )\n",
    "    \n",
    "    dataloader = DataLoader(val_dataset, batch_size=None)\n",
    "    \n",
    "    total_log_likelihood = 0.0\n",
    "    total_tokens = 0\n",
    "    \n",
    "    for batch, idx in zip(dataloader, range(25)):\n",
    "        tokens = batch.to('cuda') \n",
    "    \n",
    "        outputs = model(tokens) \n",
    "        \n",
    "        logits = outputs.logits  \n",
    "        targets = tokens[1:] \n",
    "        \n",
    "        log_probs = torch.log_softmax(logits, dim=-1)\n",
    "        \n",
    "        targets = targets.unsqueeze(-1) \n",
    "        token_log_probs = torch.gather(log_probs[:-1], dim=-1, index=targets)\n",
    "        \n",
    "        total_log_likelihood += token_log_probs.sum().item()\n",
    "        total_tokens += targets.numel()\n",
    "    \n",
    "    avg_log_likelihood = total_log_likelihood / total_tokens\n",
    "    perplexity = math.exp(-avg_log_likelihood)\n",
    "    \n",
    "    print(f\"Total Tokens: {total_tokens}\")\n",
    "    print(f\"Perplexity: {perplexity:.2f}\")\n",
    "\n",
    "    return perplexity\n",
    "\n",
    "all_data = []\n",
    "for experiment in experiments:\n",
    "    exp_path = Path('../runs/char_lm/' + experiment)\n",
    "    config_path = exp_path.joinpath('config.json')\n",
    "    with open(config_path, 'r') as f:\n",
    "        config = json.load(f)\n",
    "        \n",
    "    data = {\n",
    "        'rope_freq': config['model_config']['rotary_inv_freq_base'],\n",
    "        'is_mem': config['model_config']['mem_freq'] < 100000,\n",
    "        'is_unet': config['model_config']['unet_design'],\n",
    "        'is_embed_residual': config['model_config']['embeds_residual'],\n",
    "        'perplexity': evaluate(exp_path),\n",
    "    }\n",
    "    all_data.append(data)\n",
    "    \n",
    "data = pd.DataFrame(all_data)\n",
    "data"
   ],
   "id": "8c3c731e50da913",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../runs/char_lm/mem\n",
      "Total Tokens: 2499975\n",
      "Perplexity: 2.61\n",
      "../runs/char_lm/mem_unet\n",
      "Total Tokens: 2499975\n",
      "Perplexity: 2.58\n",
      "../runs/char_lm/baseline_rope1m\n",
      "Total Tokens: 2499975\n",
      "Perplexity: 2.63\n",
      "../runs/char_lm/baseline_rope10k\n",
      "Total Tokens: 2499975\n",
      "Perplexity: 2.62\n",
      "../runs/char_lm/baseline_rope500\n",
      "Total Tokens: 2499975\n",
      "Perplexity: 2.67\n",
      "../runs/char_lm/baseline_unet_embed\n",
      "Total Tokens: 2499975\n",
      "Perplexity: 2.59\n",
      "../runs/char_lm/mem_unet_embed\n",
      "Total Tokens: 2499975\n",
      "Perplexity: 2.57\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "   rope_freq  is_mem  is_unet  is_embed_residual  perplexity\n",
       "0  1000000.0    True    False              False    2.611141\n",
       "1  1000000.0    True     True              False    2.582623\n",
       "2  1000000.0   False    False              False    2.632282\n",
       "3    10000.0   False    False              False    2.617912\n",
       "4      500.0   False    False              False    2.670399\n",
       "5  1000000.0   False     True               True    2.585341\n",
       "6  1000000.0    True     True               True    2.572131"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rope_freq</th>\n",
       "      <th>is_mem</th>\n",
       "      <th>is_unet</th>\n",
       "      <th>is_embed_residual</th>\n",
       "      <th>perplexity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.611141</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>2.582623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.632282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.617912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>500.0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>2.670399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.585341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1000000.0</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "      <td>2.572131</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T14:06:31.850081Z",
     "start_time": "2024-12-17T14:06:31.843753Z"
    }
   },
   "cell_type": "code",
   "source": [
    "data['-perplexity'] = -data['perplexity']\n",
    "data.corr()['-perplexity']"
   ],
   "id": "73443a49b460472b",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rope_freq            0.680400\n",
       "is_mem               0.592370\n",
       "is_unet              0.827897\n",
       "is_embed_residual    0.630527\n",
       "perplexity          -1.000000\n",
       "-perplexity          1.000000\n",
       "Name: -perplexity, dtype: float64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 5
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "41ed838fe070f03f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
